

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Robots.txt Checker &mdash; CogniPrice  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Website Parser" href="../parsers.html" />
    <link rel="prev" title="Logging" href="LoggingUtil.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            CogniPrice
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto.html">Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web_crawler/config.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Parsers/impl/impl_parsers.html">Implemented Website Parsers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Queue_Handler/impl/impl_msg_queues.html">Implemented Message Queue Handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../crawler_architecture.html">Web Crawler Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web_crawler.html">Web Crawler Functionalities</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../utils.html">Web Crawler Utilities</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ConfigReader.html">Configuration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="LoggingUtil.html">Logging</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Robots.txt Checker</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../parsers.html">Website Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../queue_handler.html">Message Queue Handler</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CogniPrice</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../utils.html">Web Crawler Utilities</a></li>
      <li class="breadcrumb-item active">Robots.txt Checker</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Utils/RobotsChecker.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="robots-txt-checker">
<h1>Robots.txt Checker<a class="headerlink" href="#robots-txt-checker" title="Link to this heading"></a></h1>
<p>The <a class="reference external" href="#crawler.utils.RobotsChecker.RobotsChecker">RobotsChecker</a> class handles the validation and checking of a given URL’s crawl allowance based on the robots.txt file of the corresponding domain. It includes the following key methods:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="#crawler.utils.RobotsChecker.RobotsChecker.check_crawl_allowance">check_crawl_allowance()</a>: Checks whether the crawler is allowed to crawl a given URL by checking the domain’s robots.txt file, either from the cache or by downloading and parsing the file if it’s not cached or has expired.</p></li>
<li><p><a class="reference external" href="#crawler.utils.RobotsChecker.RobotsChecker.validate_url">validate_url()</a>: Checks if a URL is correctly formatted, specifically ensuring that it begins with “http” or “https.”</p></li>
</ul>
</div></blockquote>
<p>These methods ensure that the crawler respects domain-specific crawling policies defined in robots.txt and manages caching for efficiency. If a website does not have a robots.txt it is assumed that the website does not allow crawling.</p>
<dl class="py class" id="module-crawler.utils.RobotsChecker">
<dt class="sig sig-object py" id="crawler.utils.RobotsChecker.RobotsChecker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">crawler.utils.RobotsChecker.</span></span><span class="sig-name descname"><span class="pre">RobotsChecker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="ConfigReader.html#crawler.utils.ConfigReader.ConfigReader" title="crawler.utils.ConfigReader.ConfigReader"><span class="pre">ConfigReader</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#crawler.utils.RobotsChecker.RobotsChecker" title="Link to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="crawler.utils.RobotsChecker.RobotsChecker.check_crawl_allowance">
<span class="sig-name descname"><span class="pre">check_crawl_allowance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#crawler.utils.RobotsChecker.RobotsChecker.check_crawl_allowance" title="Link to this definition"></a></dt>
<dd><p>Checks whether crawling is allowed for a given URL according to the robots.txt policy of the host.
It first checks the robots.txt file for the domain, either from cache or by downloading and parsing it.
If the website does not allow crawling an appropriate exception is raised.
If a website does not have a robots.txt it is assumed that the website does not allow crawling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>url</strong> (<em>str</em>) – The URL to be crawled.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>True</cite> if crawling is allowed for the URL, <cite>False</cite> if not.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Exception</strong> – If there is an error fetching or parsing the robots.txt file or if the URL is invalid.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="crawler.utils.RobotsChecker.RobotsChecker.validate_url">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_url</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#crawler.utils.RobotsChecker.RobotsChecker.validate_url" title="Link to this definition"></a></dt>
<dd><p>Validates a given URL to ensure it follows the correct format (e.g., checking for ‘http’ or ‘https’).
If the URL is valid, it returns the URL as a string. If invalid, it should return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>url</strong> (<em>str</em>) – The URL to be validated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The validated URL as a string if it is valid, or None if it is invalid.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="LoggingUtil.html" class="btn btn-neutral float-left" title="Logging" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../parsers.html" class="btn btn-neutral float-right" title="Website Parser" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, CogniPrice Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>